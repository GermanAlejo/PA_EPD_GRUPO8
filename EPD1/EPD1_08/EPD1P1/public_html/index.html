<!DOCTYPE html>

<html lang="en">
    <head>
        <title>EPD1-P1</title>
    </head>
    <body>
        <div>

            <h1>Call for Labs Participation</h1>

            <p>CLEF 2016: Conference and Labs of the Evaluation Forum</p>

            <p>Information Access Evaluation meets Multilinguality, Multimodality and Interaction</p>

            <p>5-8 September 2016, &Eacute;vora - Portugal</p>

            <p>Labs registration:<p> <a href="http://clef2016-labs-registration.dei.unipd.it/">http://clef2016-labs-registration.dei.unipd.it/</a>

            <p>The CLEF Initiative (Conference and Labs of the Evaluation Forum,
                formerly known as Cross-Language Evaluation Forum)
                is a self-organized body whose main mission is to promote research, 
                innovation, and development of information access systems with an emphasis 
                on multilingual and multimodal information with various levels of structure.
            </p>

            <p>CLEF 2016 is the seventh CLEF conference continuing the popular CLEF campaigns,
                which have run since 2000 contributing to the systematic evaluation of information access systems,
                primarily through experimentation on shared tasks. CLEF 2016 consists of an independent conference and 
                a set of labs and workshops designed to test different aspects of mono and cross-language Information retrieval systems.
            </p>

            <p>Each lab focuses on a particular sub-problem or variant of the retrieval task as described below.
                Researchers and practitioners from all segments of the information access and related communities are invited to participate, 
                choosing to take part in any or all evaluation labs. At CLEF 2016 are offered seven labs and one workshop:
            </p>

            <ul>
                <li>Labs:
                    <ul>
                        <li><a href="#clef">CLEF eHealth</a></li>
                        <li><a href="#image-clef">ImageCLEF </a></li>
                        <li><a href="#life-clef">LifeCLEF</a></li>
                        <li><a href="#lab">Living Labs for IR (LL4IR)</a></li>
                        <li><a href="#rec-ev">News Recommendation Evaluation Lab (NEWSREEL)</a></li>
                        <li><a href="#pan">Uncovering Plagiarism, Authorship and Social Software Misuse (PAN)</a></li>
                        <li><a href="#sbs">Social Book Search (SBS)</a></li>
                    </ul>
                </li>

                <li>Workshop:
                    <ul>
                        <li><a href="#cmc">Cultural Microblog Contextualization (CMC)</a></li>
                    </ul>
                </li>
            </ul>

            <h2><b>Lab details</b></h2>

            <h4 id="clef">• CLEF eHealth</h4>
            <p>Usage scenario of CLEFeHealth is to ease and support patients, 
                their next-of-kins and clinical staff in understanding, accessing 
                and authoring eHealth information in a multilingual setting. 
                eHealth documents are much easier to understand after expanding shorthand,
                correcting the misspellings, normalising all health conditions to standardised terminology, 
                and linking the words to a patient-centric search on the Internet. This year, CLEF eHealth organises 3 tasks: 
            </p>

            <ul>

                <li>Task 1: Handover Information Extraction</li>
                <li>Task 2: Multilingual Information</li>
                <li>Task 3: Patient-Centered Information Retrieval</li>

            </ul>

            <ul>
                <li><b>Lab coordination:</b>
                    <ul>
                        <li>Lorraine Goeuriot (Universit&eacute; Joseph Fourier, FR - lorraine.goeuriot [at] imag.fr), </li>
                        <li>Liadh Kelly (Trinity College Dublin, IRL - liadh.kelly [at] scss.tcd.ie) </li>
                    </ul>

                <li><b>Lab Website: </b><a href="https://sites.google.com/site/clefehealth2016/">https://sites.google.com/site/clefehealth2016/</a>
            </ul>

            <h4 id="image-clef">• ImageCLEF</h4>
            <p>
                or the 2016 edition, ImageCLEF will organize three main tasks with a 
                global objective of benchmarking automatic annotation, indexing and retrieval of images. 
                The tasks tackle different aspects of the annotation and retrieval problem and are aimed at 
                supporting and promoting cutting-edge research addressing the key challenges in the field. 
                A wide range of source images and objectives are considered, 
                such as general multi-domain images for object or concept detection, 
                as well as domain-specific tasks such as labelling and separation of compound figures 
                from biomedical literature and scanned pages from historical documents. 
            </p>

            <ul>
                <li><a href="https://www.imageclef.org/2016/annotation">Image Annotation</a>
                    A task aimed at the development of systems for automatic multi-concept image annotation,
                    localization and subsequent sentence description generation. </li>
                <li><a href="https://www.imageclef.org/2016/medical">ImageCLEFmed: The Medical task </a>
                    Addresses the problems of labelling and separation of compound figures from biomedical 
                    literature and detection of bones and body part imaged in x-rays. </li>
                <li><a href="https://www.imageclef.org/2016/handwritten">Handwritten Document Retrieval </a>
                    Targets the challenge of retrieval from collections of scanned historical handwritten documents. </li>
            </ul>

            <ul>
                <li><b>Lab coordination:</b>
                    <ul>
                        <li>Mauricio Villegas (Universitat Polit&egrave;cnica de Val&egrave;ncia, SP - mauvilsa [at] upv.es) </li>
                        <li>Henning M&uuml;ller (University of Applied Sciences Western Switzerland in Sierre, CH - henning.mueller [at] hevs.ch) </li>
                    </ul>

                <li><b>Lab Website: </b><a href=" http://www.imageclef.org/2016"> http://www.imageclef.org/2016</a>
            </ul>

            <h4 id="life-clef">• LifeCLEF</h4>

            <p>
                For the 2016 edition, ImageCLEF will organize three main tasks with a global objective of benchmarking automatic annotation,
                indexing and retrieval of images. The tasks tackle different aspects of the annotation and retrieval problem and are aimed at 
                supporting and promoting cutting-edge research addressing the key challenges in the field. A wide range of source images and 
                objectives are considered, such as general multi-domain images for object or concept detection, as well as domain-specific tasks 
                such as labelling and separation of compound figures from biomedical literature and scanned pages from historical documents. 
            </p>



            <p>BirdCLEF: an audio record-based bird identification task</p>

            <p>PlantCLEF: an image-based plant identification task</p>

            <p>SeaCLEF: a visual-based sea-related organisms monitoring task </p>

            <ul>
                <li><b>Lab coordination:</b>
                    <ul>
                        <li>Alexis Joly (INRIA Sophia-Antipolis - ZENITH team, Montpellier, FR - alexis.joly [at] inria.fr) </li>
                        <li>Henning M&uuml;ller (University of Applied Sciences Western Switzerland in Sierre, CH - henning.mueller [at] hevs.ch) </li>
                    </ul>

                <li><b>Lab Website: </b><a href="  http://www.imageclef.org/node/197"> http://www.imageclef.org/node/197</a>
            </ul>

            <h4 id="lab">• Living Labs for IR (LL4IR)</h4>

            <p>
                The main goal LL4IR is to provide a benchmarking platform for researchers to evaluate their ranking
                systems in a live setting with real users in their natural task environments. 
                The lab acts as a proxy between commercial organizations (live environments) and lab participants 
                (experimental systems), facilitates data exchange, and makes comparison between the participating systems. 
            </p>

            <p>CLEF 2015 sees the second edition of the lab, which features one task: </p>
            <ul>
                <li>Task 1 - Product Search and Web Search</li>
            </ul>

            <ul>
                <li><b>Lab coordination:</b>
                    <ul>
                        <li>Krisztian Balog (University of Stavanger, N - krisztian.balog [at] uis.no) </li>
                        <li>Liadh Kelly (Dublin City University, IRL - liadh.kelly [at] scss.tcd.ie) </li>
                        <li>Anne Schuth (University of Amsterdam, NL - anne.schuth [at] uva.nl). </li>
                    </ul>

                <li><b>Lab Website: </b><a href="http://living-labs.net/clef-ll4ir-2016/">http://living-labs.net/clef-ll4ir-2016/</a>
            </ul>

            <h4 id="rec-ev">• News Recommendation Evaluation Lab (NEWSREEL)</h4>
            <p>CLEF 2016 is the third iteration of this lab.
                NEWSREEL provides two tasks designed to address the challenge of real-time news recommendation.
                Participants can: a) develop news recommendation algorithms and
                b) have them tested by millions of users over the period of a few weeks in a living lab. 
                The following tasks are offered: 
            </p>

            <ul>
                <li>Task 1 - Benchmark News Recommendations in a Living Lab: 
                    benchmarking news recommendation algorithms in a living lab environment:
                    participants will be given the opportunity to develop news recommendation algorithms 
                    and have them tested by potentially millions of users over the period of one year. </li>
                <li>Task 2 - Benchmarking News Recommendations in a Simulated Environment: 
                    simulates a real-time recommendation task using a novel recommender systems reference framework.
                    Participants in the task have to predict users' clicks on recommended news articles in simulated real time.</li>
            </ul>

            <ul>
                <li><b>Lab coordination:</b>
                    <ul>
                        <li>Frank Hopfgartner (University of Glasgow, UK - frank.hopfgartner [at] gmail.com) </li>
                        <li>Torben Brodt (plista GmbH, Berlin, DE - tb [at] plista.com) </li>
                    </ul>

                <li><b>Lab Website: </b><a href="http://www.clef-newsreel.org/">http://www.clef-newsreel.org/</a>
            </ul>

            <h4 id="pan">• Uncovering Plagiarism, Authorship and Social Software Misuse (PAN)</h4>

            <p>
                This is the 13th edition of the PAN lab on evaluation of uncovering plagiarism, 
                authorship, and social software misuse. 
                PAN offers one task at CLEF 2016 with the main goal to provide for sustainable and reproducible evaluations, 
                to get a clear view of the capabilities of state-of-the-art-algorithms.
            </p>

            <ul>
                <li>Task 1 - PAN Lab on Digital Text Forensics </li>
            </ul>

            <ul>
                <li><b>Lab coordination:</b>
                    <ul>
                        <li>Martin Potthast (Bauhaus-Universit&auml;t Weimar, DE), </li>
                        <li>Benno Stein (Bauhaus-Universit&auml;t Weimar, DE), </li>
                        <li>Paolo Rosso (Universitat Polit&egrave;cnica de Val&egrave;ncia, SP), </li>
                        <li>Efstathios Stamatatos (University of the Aegean, GR). </li>
                    </ul>

                <li><b>Lab Website: </b><a href="http://pan.webis.de">http://pan.webis.de</a>
            </ul>

            <h4 id="sbs">• Social Book Search (SBS)</h4>

            <p>
                The Social Book Search (SBS) Lab investigates book search in scenarios where users search with more than just a query, 
                and look for more than objective metadata. Real-world information needs are generally complex,
                yet almost all research focuses instead on either relatively simple search based on queries or 
                recommendation based on profiles. The goal is to research and develop techniques to support users in complex book search tasks. 
                The Social Book Search Lab consists of three tracks:
            </p>

            <ul>

                <li>Interactive Track: a user-oriented interactive task investigating
                    systems that support users in each of multiple stages of a complex search tasks.
                    The track offers participants a complete experimental interactive IR setup and an 
                    exciting new multistage search interface to investigate how users move through search stages. </li>
                <li>Suggestion Track: a system-oriented task to suggest books based on rich search requests
                    combining several topical and contextual relevance signals, 
                    as well as user profiles and real-world relevance judgements. </li>
                <li>Mining Track: an NLP/Text Mining track focussing on supporting users
                    in discussion forums by detecting and linking book titles and author names to entity metadata. </li>
            </ul>

            <ul>
                <li><b>Lab coordination:</b>
                    <ul>

                        <li>Jaap Kamps, Marijn Koolen, Hugo Huurdeman (University of Amsterdam, NL - kamps [at] uva.nl, marijn.koolen [at] uva.nl, h.c.huurdeman [at] uva.nl)</li>

                        <li>Toine Bogers, Mette Skov (Aalborg University, Copenhagen, DK - toine [at] hum.aau.dk, skov [at] hum.aau.dk)</li>

                        <li>Mark Hall (Edge Hill University, Ormskirk, UK - hallmark [at] edgehill.ac.uk)</li>

                        <li>Marijn Koolen (University of Amsterdam, NL - marijn.koolen [at] uva.nl)</li>

                        <li>Hugo Huurdeman (University of Amsterdam, NL - h.c.huurdeman [at] uva.nl</li>

                        <li>Mette Skov (Aalborg University Copenhagen, DK - skov [at] hum.aau.dk)</li>
                    </ul>
                <li><b>Lab website: </b><a href="http://social-book-search.humanities.uva.nl/#/overview">http://social-book-search.humanities.uva.nl/#/overview</a></li>
            </ul>

            <h2><b>Workshop details</b></h2>

            <h4 id="cmc">• Cultural Microblog Contextualization (CMC)</h4>
            <p>Cultural Microblog Contextualization CLEF 2016 WorkShop aims at developing
                processing methods and resources to mine the social media sphere surrounding 
                cultural events such as festivals. Tweets linked to an event make a dense, 
                rich but very noisy corpus. Content is often imprecise, duplicate, or non-informative. 
                For its first edition, this WorkShop will give access for registered participants to a massive collection of microblogs, 
                urls and images all related to cultural festivals in the world. This access will allow researchers in IR and NLP to 
                experiment large scale multilingual microblog search, WikiPedia entity search, and automatic summarization.
                Extensive textual references will be provided by organizers. The following tasks are offered: 
            </p>

            <ul>
                <li>Task 1 - Cultural Multilingual microblog contextualization based on WikiPedia</li>
                <li>Task 2 - Cultural MicroBlog Search based on WikiPedia entities</li>
                <li>Task 3 - TimeLine illustration based on Microblogs</li>
            </ul>

            <ul>
                <li><b>Coordination:</b>
                    <ul>

                        <li>Georges Linar&egrave;s and Eric SanJuan (Universit&eacute; d'Avignon, FR - firstname.lastname [at] univ-avignon.fr)</li>

                        <li>Lorraine Goeuriot and Philippe Mulhem (Universit&eacute; Grenoble Alpes, FR - firstname.lastname [at] imag.fr)</li>

                        <li>Josiane Mothe (Institut de Recherche en Informatique de Toulouse, FR - mothe [at] irit.fr)</li>
                    </ul>
                <li><b>Website: </b><a href="https://mc2.talne.eu/~cmc/spip/">https://mc2.talne.eu/~cmc/spip/</a></li>
            </ul>

            <h2><b>Lab registration</b></h2>
            <p>Participants must register for tasks via the following website: </p>
            <a href="http://clef2016-labs-registration.dei.unipd.it/">http://clef2016-labs-registration.dei.unipd.it/</a>

            <h4><b>Data</b></h4>
            <p>The training and test data are provided by the organizers, 
                which allow participating systems to be evaluated and compared in a systematic way. 
            </p>

            <h4><b>Worshops</b></h4>
            <p>
                The Lab Workshop sessions will take place within the CLEF 2016 conference at the conference site in &Eacute;vora.
                Lab coordinators will present a summary of their lab in an overview
                presentations during the plenary scientific paper sessions in the CLEF 2016 conference, 
                to allow non-participants to gain an overview of the motivation, objectives,
                outcomes and future challenges of each Lab. The separate Lab Workshop 
                sessions provide a forum for participants to present their results (including failure analyses and system comparisons),
                description of retrieval techniques used, and other issues of interest to researchers in the field. 
                Participating groups will be invited to present their results in a joint poster session. 
            </p>

            <h4><b>Publication</b></h4>
            <p>All groups participating each evaluation Lab are asked to submit a paper for the CLEF 2016 Working Notes.
                These will be published in the online CEUR-WS Proceedings and on the conference website.
            </p>
            <p>
                Two different and separate types of overviews will be produced by Lab Organizers, one for the Online Working Notes, 
                and one for Conference Proceedings (published by Springer in their Lecture Notes for Computer Science - LNCS series).
            </p>

            <h4><b>Timeline</b></h4>

            <p>
                The timeline for 2016 Labs is as follows: 
            </p>

            <ol>
                <li>Labs registration opens: October 30, 2015</li>

                <li>Registration closes: April 22, 2016</li>

                <li>End Evaluation Cycle: May 4, 2016</li>

                <li>Submission of Participant Papers [CEUR-WS]: May 25, 2016</li>

                <li>Submission of Lab Overviews [LNCS]: June 3, 2016</li>

                <li>Notification of Acceptance Lab Overviews [LNCS]: June 10, 2016</li>

                <li>Camera Ready Copy of Lab Overviews [LNCS] due: June 17, 2016</li>

                <li>Notification of Acceptance Participant Papers [CEUR-WS]: June 17, 2016</li>

                <li>Camera Ready Copy of Participant Papers and Extended Lab Overviews [CEUR-WS] due: July 1, 2016</li>
            </ol>

            <h2><b>Organization</b></h2>

            <h4>Conference Chairs:</h4>
            
            <ul>
                <li>Norbert Fuhr, University of Duisburg-Essen, Germany</li>

                <li>Paulo Quaresma, University of &Eacute;vora, Portugal</li>
            </ul>
            
            
            <h4>Program Chairs:</h4>
            
            <ul>
                <li> Birger Larsen, University of Aalborg, Denmark</li>

                <li> Teresa Gon&ccedil;alves, University of &Eacute;vora, Portugal</li>
            </ul>
            
            
            <h4>Lab chairs:</h4>
            
            <ul>
                <li>Craig Macdonald, University of Glasgow, UK</li>

                <li>Krisztian Balog, University of Stavenger, Norway</li>
            </ul>
            
            
            <h4>Lab committee:</h4>
            
            <ul>
                <li>Martin Braschler, Zurich University of Applied Sciences, Switzerland</li>

                <li>Nicola Ferro, University of Padua, Italy</li>

                <li>Donna Harman, National Institute for Standards and Technology (NIST), USA</li>

                <li>Maarten de Rijke, University of Amsterdam UvA, The Netherlands</li>
            </ul>
            
            
            <h4>Local organization committee:</h4>
            
            <ul>
                <li>Irene Rodrigues, University of &Eacute;vora, Portugal</li>

                <li>Jos&eacute; Saias, University of &Eacute;vora, Portugal</li>

                <li>Lu&iacute;s Rato, University of &Eacute;vora, Portugal</li>
            </ul>
            
            
            <h4>Proceedings Chairs:</h4>
            
            <ul>
                <li>Linda Cappellato, University of Padua, Italy</li>

                <li>Nicola Ferro, University of Padua, Italy</li>
            </ul>

        </div>
    </body>
</html>
